# LLM超入門

生成AIについての基礎知識を得るをために手に取った超入門シリーズの一冊。

## LLMに関連する基礎用語

| 用語 | 説明 |
|:-----|:-----|
| AI | 人間の知能を模倣したコンピュータシステムの研究領域 |
| ニューラルネットワーク | 人間の脳の仕組みを模倣したコンピュータアルゴリズム |
| 深層学習 | ニューラルネットワークを基にした学習手法で、大量のデータからパターンを学ぶ。<br/>画像認識、音声認識、自然言語処理などの領域に革新をもたらした。 |
| 自然言語処理（NLP） | AIが人間の言語を理解し生成する能力の研究領域。<br />NLGと区別して生成を除いて理解と分析に限定して用いられることもあるらしい。 |
| 自然言語生成（NLG） | 人間が読みやすい自然言語のテキストを生成するAIの分野。 |
| 言語モデル | 自然言語の統計的な特性を捉え、特定の文がどの程度自然なのかを評価するもの。<br />より具体的には、一連の単語が与えられた時に次に来る単語が何であるか予測するための確率モデル。 |
| N-gram | 初期の言語モデル。<br />特定の単語が前のN個の単語に続く確率を学習したが、限界があった。 |
| ニューラル言語モデル| N-gramに代わって脚光を浴びた、ニューラルネットワークを基にして開発された言語モデル。 |
| 大規模言語モデル（LLM） | 大量のテキストデータから学習する言語モデルの一種で、多くのNLPタスクに対応する能力を持っている。<br />学習にはトランスフォーマーという深層学習モデルの一種が使われるが、その特徴として自己注意機構（Self-Attention Mechanism）『各単語と他の全ての単語との関係を捉えられる』がある。<br />LLMの訓練には大部分が教師なし学習（Unsupervised Learning）が用いられるが、特定のタスクに対する性能を向上させるために教師あり学習（Supervised Learning）でのファインチューニングが行われることもある。<br />パフォーマンス評価には人間が評価する定性評価と、精度や再現率などの定量評価が含まれる |
| GPT（Generative Pretrained Transformer） | OpenAI社が開発したAIモデルのシリーズ名 |
| ChatGPT | チャットbotのUIでGPTを使用できるサービス |
| ファインチューニング | 既存のモデルを特定のタスクに適応させるための一般的な手法で、少量のデータで既存モデルの再訓練を行う |
| ゼロ,ワン,フューショット学習| LLMが新しいタスクにどのように適応するかを表す概念。<br />事前に学習する例がそれぞれ0,1,複数であることを意味する。 |
| 前処理 | モデルの学習を効率的にするためトークン化の前に実施されるプロセスで、テキストのクリーニング、ノイズ除去、正規化などが含まれる |
| トークン | テキストに含まれる意味のある単位のことで、単語ベースのトークン化が最も一般的に用いられる |
| 語彙サイズ | 大規模言語モデルが認識できるユニークなトークン数 |
| 損失関数（Loss Function） | モデルの訓練は損失関数を最小化するようパラメータ調整しながら行われる。<br />LLMでは一般的に交差エントロピー損失関数が使用される。 |
| 過学習 | モデルが訓練データに対して過度に適合し、新しいデータに対する汎化能力を損なう現象 |
| 正規化 | 過学習を防ぐために使われる手法で、モデルの複雑さを制限し、パラメータの値が大きくなりすぎるのを防ぐ |

## LLMの課題

- 訓練データに含まれる個人情報、偏見、差別といった内容も学習し保持してしまう。
- 生成内容に制限がないため、倫理・法・真実性など複数の観点で不適切な内容を生成する可能性がある。
- LLMが生成するコンテンツの著作権について未だ明確な定義が存在せず、存在しないこと自体が生成物を使用することによる問題発生の可能性を示している。

